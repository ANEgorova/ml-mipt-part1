\documentclass[a4paper, 12pt]{article}				

%============== Русский язык ===============================
\usepackage[T2A]{fontenc}		
\usepackage[utf8]{inputenc}	
\usepackage[english,russian]{babel}	
\usepackage{multicol}
\usepackage{minted}

%============== Всякие пакеты ===============================
% нужно поставить pygments - $ sudo pip install pygments
\usepackage{listings, minted, chngcntr, float, amsmath, amssymb, cmap, graphicx, xcolor, hyperref, geometry}

 \geometry{
 	a4paper,
 	total={210mm,297mm},
 	left=20mm,
 	right=20mm,
 	top=20mm,
 	bottom=20mm,
 }

%============== Цветные гиперссылки =========================
\definecolor{wine-stain}{rgb}{1,0,0}
\hypersetup{colorlinks, linkcolor=wine-stain, linktoc=all}

%============== Настройка листингов =========================
\usemintedstyle{default}
\definecolor{codebg}{rgb}{0.96,0.96,0.96}

\renewcommand\listoflistingscaption{Листинги}
\renewcommand\listingscaption{Листинг}

% === Это магия, чтоб все с рускими буквами хорошо в листиге было
% === Это макрос, чтоб не писать рараметры каждый раз

\makeatletter
\newenvironment{mycode}[3]
{\VerbatimEnvironment
	\minted@resetoptions
	\setkeys{minted@opt}{bgcolor=codebg, linenos=true, frame=lines, numbersep=5pt, tabsize=4}
	\renewcommand{\minted@proglang}[1]{#1}
	\begin{listing}[H]%% default placing
		\centering
		\caption{#2}\label{#3}
		\begin{VerbatimOut}{\jobname.pyg}}
		{\end{VerbatimOut}
		\minted@pygmentize{\minted@proglang{}}
		\DeleteFile{\jobname.pyg}
	\end{listing}}
	\makeatother
%================ Всякое разное форматирование ========================

\textheight=27cm 		% высота текста
\textwidth=19cm 		% ширина текста
\oddsidemargin=-1.5cm 		% отступ от левого края
\topmargin=-3.0cm 		% отступ от верхнего края
\parindent=24pt 		% абзацный отступ
\parskip=0pt 			% интервал между абзацами
\tolerance=2000	 		% терпимость к "жидким" строкам
\flushbottom 			% выравнивание высоты страниц

\parindent=0cm
\title{MIPT HW 1}
%===================================================================
%===================================================================
%===================================================================
%===================================================================

\begin{document}

  \begin{center}
    \textsc{\textbf{
    	{\Large Машинное Обучение МФТИ \\
        \vspace{0.5cm}
    	Практическое задание №1: Метрические Алгоритмы}}}
  \end{center}

\begin{center}
	\includegraphics[scale=1.0]{mnist}
\end{center}

В качестве первой домашней работы студентам предлагается принять участие в соревновании по распознаванию рукописных цифр на Kaggle. Для выполнения домашнего задания используйте ipython notebook с небольшими заготовками кода.

Соревнование общее -- бонусы получают три первые места в каждой учебной группе.

\subsection*{Настройка окружения, инструкция по отправке решения}
  \begin{enumerate}
	\item Вы можете загрузить \texttt{01\_knn\_start\_code.zip}, в этом файле находится ноутбук с кодом, который необходимо доделать, следуя инструкциям =).
    \item Установите \href{https://www.continuum.io/downloads}{https://www.continuum.io/downloads} для \textbf{Python 2.7} -- это важно. 
    \item Для настройки окружения задания выполните 
        \begin{minted}{bash}
            unzip 01_knn_start_code.zip 
            cd 01_knn_start_code
            pip install -r req.txt
            ipython notebook
		\end{minted}
     \item Сохранить ipnb с выполненным экспериментом. Нужно запаковать, переименовать \texttt{01\_knn\_start\_code\_<фамилия>.zip } и отправить в приватный канал в piazza. В ноутбуке должны быть описаны эксперименты, которые показали улучшение. Приведен код который их выполняет. Можете описать интересные идеи которые не сработали. 
  \end{enumerate}

\subsection*{Описание данных и метрики}
Для решения задания нужно обучить модель на обучающей выборке \texttt{train.csv}, сделать предсказание на \texttt{validation.csv} и оправить свое решение на kaggle. Для ранжирования решений на \texttt{ladboard} используется метрика \emph{accuracy}~--~доля правильно классифицированы объектов в валидационной выборке. 

$$Accuracy = \frac{num~right~answers}{num~all~answers} = \frac{\sum_i^N [\hat{y}_i = y_i]}{N}$$

Каждый объект в обучающей выборке (\texttt{train.csv}) представляет собой черно белое квадратное изображение размера 27 пикселя и метку класса, к которому относится этот обект. Изображение построчно вытянуто в одну большую строку размера $27\cdot27 = 729$ в каждом элементе с индексом $row\cdot27 + column$ находится интенсивность $I_{row, clumn}$ пикселся. 

\subsection*{Задания которое нужно выполнить}
\begin{enumerate}
	\item Визуализируйте внутриклассовые центры 
	\item Реализовать метод K-ближайших соседей с метрикой L2:
      \begin{enumerate}
          \item Матрицей попарных расстояний используя: 2 цикла, 1 цикл, не используя циклов
          \item KD tree (используйте класс \texttt{sklearn.neighbors.KDTree})
      \end{enumerate}
	В чем достоинства и недостатки предложенных методов, какие улучшения можно предложить? 
    
    \item Реализуйте алгоритм кросс валидации
    \item Настройте параметры алгоритма: число ближайших соседей, метрику, ядро. Визуализируйте  зависимость качества от настраиваемых параметров.
    \item На основе отступа реализуйте удаление шумовых объектов, улучшилось ли-качество, почему это произошло?
    \item Для того, чтобы заданнее было оценено выше 0 баллов, ваше итоговое решение должно превысить превысить KNN-бенчмарк 
    \item \textcolor{red}{[Придумайте сами]} Получите улучшение за сечет различных модификаций: 
    	\begin{enumerate}
			\item метрических алгоритмов
            \item преобразований на объектами обучающей выборки
		\end{enumerate}
    \item \textbf{Задание считается сданным после отправки ipython notebook, с описанием и кодом проведенных экспериментов, наглядными графиками и правильными выводами} 
\end{enumerate}

\subsection*{Методические указания}
  \begin{enumerate}
  \item При подборе параметров модели рекомендуется использовать только часть обучающей выборки, для того чтобы сократить время обучения. 
  \item Согласно правилам соревнований нельзя делать больше 2х коммитов в систему в сутки. Из этого надо сделать следующие выводы:
  \begin{enumerate}
      \item Обучаться нужно локально (cross validation) и только после получения результата, который вы считаете удовлетворительным, нужно делать submit в систему.
      \item Начать делать домашнее задание стоит заблаговременно. 
  \end{enumerate}
  \item Обратите внимание, что публичные результаты на kaggle рассчитываются только по части контрольной выборки, и будут рассчитаны по всей контрольной выборке после окончания соревнования. Будьте аккуратны с переобучением.  
  \item Победители получают бонусные балы -- шарить решение не выгодно.
\end{enumerate}
\vspace{5cm}
\emph{Разница между списыванием и помощью товарища иногда едва различима. Мы искренне надеемся, что при любых сложностях вы можете обратиться к семинаристам и с их подсказками самостоятельно справиться с заданием. При зафиксированных случаях списывания (одинаковый код, решение задачи), баллы за задание будут обнулены всем участникам инцидента.}

\end{document}