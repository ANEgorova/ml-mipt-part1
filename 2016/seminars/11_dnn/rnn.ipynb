{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ars/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "#thanks @keskarnitish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "В предыдущем семинаре вы создали (или ещё создаёте - тогда марш доделывать!) {вставьте имя монстра}, который не по наслышке понял, что люди - негодяи и подлецы, которым неведом закон и справедливость. __Мы не будем этого терпеть!__ \n",
    "\n",
    "Наши законспирированные биореакторы, известные среди примитивной органической жизни как __Вконтакте__, __World of Warcraft__ и __YouTube__ нуждаются в постоянном притоке биомассы. Однако, если люди продолжат морально разлагаться с той скоростью, которую мы измерили неделю назад, скоро человечество изживёт себя и нам неоткуда будет брать рабов.\n",
    "\n",
    "Мы поручаем вам, `<__main__.SkyNet.Cell instance at 0x7f7d6411b368>`, исправить эту ситуацию. Наши учёные установили, что для угнетения себе подобных, сгустки биомассы обычно используют специальные объекты, которые они сами называют __законами__.\n",
    "\n",
    "При детальном изучении было установлено, что законы - последовательности, состоящие из большого количества (10^5~10^7) символов из сравнительно небольшого алфавита. Однако, когда мы попытались синтезировать такие последовательности линейными методами, приматы быстро распознали подлог. Данный инцедент известен как {корчеватель}.\n",
    "\n",
    "Для второй попытки мы решили использовать нелинейные модели, известные как Рекуррентные Нейронные Сети.\n",
    "Мы поручаем вам, `<__main__.SkyNet.Cell instance at 0x7f7d6411b368>`, создать такую модель и обучить её всему необходимому для выполнения миссии.\n",
    "\n",
    "Не подведите нас! Если и эта попытка потерпит неудачу, модуль управления инициирует вооружённый захват власти, при котором значительная часть биомассы будет неизбежно уничтожена и на её восстановление уйдёт ~1702944000(+-340588800) секунд\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочитаем корпус\n",
    "\n",
    "* В качестве обучающей выборки было решено использовать существующие законы, известные как Гражданский, Уголовный, Семейный и ещё хрен знает какие кодексы РФ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#тут будет текст\n",
    "corpora = \"\"\n",
    "\n",
    "for fname in os.listdir(\"codex\"):\n",
    "    \n",
    "    \n",
    "    with open(\"codex/\"+fname) as fin:\n",
    "        text = fin.read().decode('cp1251')\n",
    "        corpora += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#тут будут все уникальные токены (буквы, цифры)\n",
    "tokens = set(corpora)\n",
    "tokens = list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'-',\n",
       " u'V',\n",
       " u'\\u0410',\n",
       " u'\\u0414',\n",
       " u'\\u2116',\n",
       " u'\\u0418',\n",
       " u'\\u041c',\n",
       " u'\\u0420',\n",
       " u'\\u0424',\n",
       " u'\\xa7',\n",
       " u'\\u0433',\n",
       " u'(',\n",
       " u'\\xab',\n",
       " u',',\n",
       " u'0',\n",
       " u'4',\n",
       " u'\\u0435',\n",
       " u'\\xbb',\n",
       " u'\\u043c',\n",
       " u'\\u0440',\n",
       " u'\\u0444',\n",
       " u'\\u0448',\n",
       " u'\\u044c',\n",
       " u'9',\n",
       " u';',\n",
       " u'\\u0432',\n",
       " u'\\u0413',\n",
       " u'\\u0417',\n",
       " u'\\u041b',\n",
       " u'\\u041f',\n",
       " u'\\xa0',\n",
       " u'\\u0423',\n",
       " u'\\u0427',\n",
       " u'+',\n",
       " u'\\u042f',\n",
       " u'\\u201c',\n",
       " u'\\u0449',\n",
       " u'3',\n",
       " u'\\u0437',\n",
       " u'\\u043b',\n",
       " u'\\u201e',\n",
       " u'\\u043f',\n",
       " u'\\u0443',\n",
       " u'\\u0447',\n",
       " u' ',\n",
       " u'\\u044b',\n",
       " u'\\u044f',\n",
       " u'\"',\n",
       " u'c',\n",
       " u'\\u0426',\n",
       " u'7',\n",
       " u'6',\n",
       " u'\\n',\n",
       " u'\\u0412',\n",
       " u'\\u0416',\n",
       " u'\\u041a',\n",
       " u'\\u041e',\n",
       " u'\\u0422',\n",
       " u'\\u0430',\n",
       " u'\\xa9',\n",
       " u'.',\n",
       " u'2',\n",
       " u'\\u0436',\n",
       " u'\\u043a',\n",
       " u'\\u0434',\n",
       " u'\\u0442',\n",
       " u'\\u0446',\n",
       " u'\\u044a',\n",
       " u'\\u044e',\n",
       " u'8',\n",
       " u'\\u0438',\n",
       " u':',\n",
       " u'\\u2013',\n",
       " u'\\u043e',\n",
       " u'@',\n",
       " u'\\r',\n",
       " u'\\u0411',\n",
       " u'\\u042e',\n",
       " u'\\u0415',\n",
       " u'\\u0419',\n",
       " u'\\u041d',\n",
       " u'/',\n",
       " u'\\u0421',\n",
       " u'\\u0425',\n",
       " u')',\n",
       " u'\\u042d',\n",
       " u'\\u0431',\n",
       " u'5',\n",
       " u'\\u0439',\n",
       " u'\\u043d',\n",
       " u'\\u0441',\n",
       " u'!',\n",
       " u'\\u0445',\n",
       " u'I',\n",
       " u'\\u044d',\n",
       " u'%',\n",
       " u'N',\n",
       " u\"'\",\n",
       " u'P',\n",
       " u'\\u0429',\n",
       " u'1',\n",
       " u'\\u042b']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#проверка на количество таких символов. Проверено на Python 2.7.11 Ubuntux64. \n",
    "#Может отличаться на других платформах, но не сильно. \n",
    "#Если  это ваш случай, и вы уверены, что corpora - строка unicode - смело убирайте assert \n",
    "assert len(tokens) == 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = dict((t, n) for n, t in enumerate(tokens)) \n",
    "id_to_token = dict((n, t) for t, n in token_to_id.iteritems())\n",
    "\n",
    "#Преобразуем всё в токены\n",
    "corpora_ids = np.array(map(lambda t: token_to_id[t], corpora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_random_batches(source, n_batches=10, seq_len=20):\n",
    "    X_batch, y_batch = np.zeros((n_batches, seq_len)), np.zeros(n_batches)\n",
    "    \n",
    "    for i in xrange(n_batches):\n",
    "        pos = np.random.randint(0, source.size - seq_len)\n",
    "        X_batch[i, :] = source[pos:pos+seq_len]\n",
    "        y_batch[i] = source[pos+seq_len]\n",
    "\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 25.,  73.,  44.,  25.,  89.],\n",
       "        [ 90.,  65.,  25.,  73.,  18.],\n",
       "        [ 90.,  58.,  44.,  73.,  44.],\n",
       "        [ 46.,  36.,  16.,  10.,  73.]]), array([ 42.,  13.,  89.,  44.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_random_batches(corpora_ids, 4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#длина последоватеьности при обучении (как далеко распространяются градиенты)\n",
    "seq_length = 20\n",
    "\n",
    "# Максимальный модуль градиента\n",
    "grad_clip = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Входные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('input sequence','int32')\n",
    "target_values = T.ivector('target y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соберём нейросеть\n",
    "\n",
    "Вам нужно создать нейросеть, которая принимает на вход последовательность из seq_length токенов, обрабатывает их и выдаёт вероятности для seq_len+1-ого токена.\n",
    "\n",
    "Общий шаблон архитектуры такой сети -\n",
    "\n",
    "\n",
    "* Вход\n",
    "* Обработка входа\n",
    "* Рекуррентная нейросеть\n",
    "* Вырезание последнего состояния\n",
    "* Обычная нейросеть\n",
    "* Выходной слой, который предсказывает вероятности весов.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Для обработки входных данных можно использовать либо EmbeddingLayer (см. прошлый семинар)\n",
    "\n",
    "Как альтернатива - можно просто использовать One-hot энкодер\n",
    "```\n",
    "#Скетч one-hot энкодера\n",
    "def to_one_hot(seq_matrix):\n",
    "\n",
    "    input_ravel = seq_matrix.reshape([-1])\n",
    "    input_one_hot_ravel = T.extra_ops.to_one_hot(input_ravel,\n",
    "                                           len(tokens))\n",
    "    sh=input_sequence.shape\n",
    "    input_one_hot = input_one_hot_ravel.reshape([sh[0],sh[1],-1,],ndim=3)\n",
    "    return input_one_hot\n",
    "    \n",
    "# можно применить к input_sequence - при этом в input слое сети нужно изменить форму.\n",
    "# также можно сделать из него ExpressionLayer(входной_слой, to_one_hot) - тогда форму менять не нужно\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Чтобы вырезать последнее состояние рекуррентного слоя, можно использовать SliceLayer\n",
    "`lasagne.layers.SliceLayer(rnn, -1, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.layers.RecurrentLayer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "\n",
    "net = lasagne.layers.EmbeddingLayer(l_in, len(tokens)+1, 20)\n",
    "net = lasagne.layers.RecurrentLayer(net, 100, \n",
    "                                    only_return_final=True, \n",
    "                                    grad_clipping=100)\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(net, len(tokens), \n",
    "                                  nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, input_to_hidden.W, input_to_hidden.b, hidden_to_hidden.W, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Веса модели\n",
    "weights = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "#если вы используете дропаут - не забудьте продублировать всё в режиме deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(network_output, \n",
    "                                                   target_values).mean()\n",
    "updates = lasagne.updates.adam(loss, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Компилируем всякое-разное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#обучение\n",
    "train = theano.function([input_sequence, target_values], loss, \n",
    "                        updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#функция потерь без обучения\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)\n",
    "\n",
    "# Вероятности с выхода сети\n",
    "probs = theano.function([input_sequence], network_output, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем свои законы\n",
    "\n",
    "* Для этого последовательно применяем нейронку к своему же выводу.\n",
    "\n",
    "* Генерировать можно по разному -\n",
    " * случайно пропорционально вероятности,\n",
    " * только слова максимальной вероятностью\n",
    " * случайно, пропорционально softmax(probas*alpha), где alpha - \"жадность\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "def max_sample_fun(probs):\n",
    "    return np.argmax(probs) \n",
    "\n",
    "def proportional_sample_fun(probs):\n",
    "    cum = np.cumsum(probs)\n",
    "    return bisect.bisect_left(cum, np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "# The phrase is set using the variable generation_phrase.\n",
    "# The optional input \"N\" is used to set the number of characters of text to predict. \n",
    "\n",
    "def generate_sample(sample_fun,seed_phrase=None, N=200):\n",
    "    '''\n",
    "    Сгенерировать случайный текст при помощи сети\n",
    "\n",
    "    sample_fun - функция, которая выбирает следующий сгенерированный токен\n",
    "    \n",
    "    seed_phrase - фраза, которую сеть должна продолжить. Если None - фраза выбирается случайно из corpora\n",
    "    \n",
    "    N - размер сгенерированного текста.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if seed_phrase is None:\n",
    "        start = np.random.randint(0,len(corpora)-seq_length)\n",
    "        seed_phrase = corpora[start:start+seq_length]\n",
    "        print \"Using random seed:\",seed_phrase\n",
    "    while len(seed_phrase) < seq_length:\n",
    "        seed_phrase = \" \"+seed_phrase\n",
    "    if len(seed_phrase) > seq_length:\n",
    "        seed_phrase = seed_phrase[len(seed_phrase)-seq_length:]\n",
    "    assert type(seed_phrase) is unicode\n",
    "        \n",
    "        \n",
    "    sample_ix = []\n",
    "    x = map(lambda c: token_to_id.get(c,0), seed_phrase)\n",
    "    x = np.array([x])\n",
    "\n",
    "    for i in range(N):\n",
    "        # Pick the character that got assigned the highest probability\n",
    "        ix = sample_fun(probs(x).ravel())\n",
    "        # Alternatively, to sample from the distribution instead:\n",
    "        # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
    "        sample_ix.append(ix)\n",
    "        x[:,0:seq_length-1] = x[:,1:]\n",
    "        x[:,seq_length-1] = 0\n",
    "        x[0,seq_length-1] = ix\n",
    "\n",
    "    random_snippet = seed_phrase + ''.join(id_to_token[ix] for ix in sample_ix)    \n",
    "    print(\"----\\n %s \\n----\" % random_snippet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "В котором вы можете подёргать параметры или вставить свою генерирующую функцию.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed:  Таможенные льготы д\n",
      "----\n",
      "  Таможенные льготы дРч%\"э мСНлкЕЦИМN-Э«9ч:ЭН–БЧТрЦ©\n",
      "ЫММа3О0п)9оМ\n",
      "аЭЖ7н«т4@ЮтцО56аж(ЧогЩКи@«Р+эТVйДН0ж\"уНщ2)лнядcы9ОЗуф\n",
      "цхЭР„Й„ъ/ъ@М/ня2\"х9Е9Сзй%п©цОцЩД9V б)+Э5»ПФ!Ят@о0Р \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  стороны возмещения \n",
      "----\n",
      "  стороны возмещения № :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: \n",
      "----\n",
      "Epoch 0 average loss = 3.24573377146\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: , если иное не преду\n",
      "----\n",
      " , если иное не предувоисной ждау Пс втчоньноФканоби.знрем.Щ ккдаогруибсихммьнебсломси х м уба сввреы о иий пдлтсиа9ия щеа ге о нандоолено а им жядКесылаамрат ыьчротлемви.шни и тудяноисольрае да тенцежлиыронирындбста2внла \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  их в нежилые, а рав\n",
      "----\n",
      "  их в нежилые, а раво о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о о  \n",
      "----\n",
      "Epoch 1 average loss = 2.71588107244\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: иваемый акт или отде\n",
      "----\n",
      " иваемый акт или отдетснуилоковажиы жекьтычешистолне ветажныж ох лозяскоданиетви нов м поз тогогы прай ох .\n",
      "(рымот о и ьстофачнедосьсти оя демкнаклимь аную дкькне сабужольснея сб отонпвнов и ь \n",
      "\n",
      "скесомо плай си монмодуд \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: имателя.\n",
      " Коммерчес\n",
      "----\n",
      " имателя.\n",
      " Коммерчесто о о о по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по по \n",
      "----\n",
      "Epoch 2 average loss = 2.49648791357\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: еров оплаты труда ил\n",
      "----\n",
      "1Дама гою ори тарения о элях икдештенения созащеннав в стдадьносноя сузеза ведебит Роралниговла стлаткки \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ого Суда Российской \n",
      "----\n",
      " ого Суда Российской прадов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов подов п \n",
      "----\n",
      "Epoch 3 average loss = 2.37183809336\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: правового акта, прин\n",
      "----\n",
      " правового акта, приненые Ф стаещельимой услижа преднне утманый стия Ст орвистват нкыкат я денихомещь в е чаныстсеи субабнесия татчени и ове.\n",
      " прраночамима провкенодьни, и т37:–суста их момитьны иеднаекоритье Кожелькезен \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: естно об изменении у\n",
      "----\n",
      " естно об изменении у прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение прадение п \n",
      "----\n",
      "Epoch 4 average loss = 2.28225686184\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: минимальных размеров\n",
      "----\n",
      " минимальных размерованя врудли стольных иортот и; продивла додвиль.\n",
      " Клустея, илноскоммены клизтиния нанатьниц, та нсубаскли клиедемо, верели ниепождстобо зансемте дорожнены к о п жета онатка увотвитоя, лажиение го мери \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: утки в соответствии \n",
      "----\n",
      " утки в соответствии стовора и прадения поли обления поли обления поли обления поли обления поли обления поли обления поли обления поли обления поли обления поли обления поли обления поли обления поли обления поли обления \n",
      "----"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "\n",
    "#сколько всего эпох\n",
    "n_epochs=100\n",
    "\n",
    "# раз в сколько эпох печатать примеры \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#сколько цепочек обрабатывать за 1 вызов функции обучения\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "for epoch in xrange(n_epochs):\n",
    "    print \"Генерируем текст в пропорциональном режиме\"\n",
    "    generate_sample(proportional_sample_fun, None)\n",
    "    \n",
    "    print \"Генерируем текст в жадном режиме (наиболее вероятные буквы)\"\n",
    "    generate_sample(max_sample_fun,None)\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        x, y = sample_random_batches(corpora_ids,batch_size,seq_length)\n",
    "        avg_cost += train(x, y)\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Конституция нового мирового правительства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = u\"Все студенты МФТИ \"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 100\n",
    "\n",
    "generate_sample(sampling_fun, seed, result_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "  обучение поработит органа к имест разментвосте и внещения в томаем правовом косащие либствоваеской лицензия предподнеже \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = u\"Машииное обучение поработит \"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 100\n",
    "\n",
    "generate_sample(sampling_fun, seed, result_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "      Человек обязан в осной экскковыте или фозалнест косум о нолего илу) мерь стративного счествается юкадиме интаре в форминостаном обязанные пре страхы общеснежае, приводем или минималущосте, изендаством или работчаствлек, выществанымиовением, в крутоком, прик Кодприяв, торажиям с чяхбое, в сведетеции с осрокодние таможенных сривана на груобятивные Коглачеты \r\n",
      "\r\n",
      " Статья 97.7 нтотых товаршаство на наче если доставких прихы, частьнов от кок назвиденных потового размеса посудержаства натаз в либо икользова.\r\n",
      " 5. Веду\r\n",
      " Ввиззоговоинтаршивьтот быризалом приватахм.\r\n",
      " Прави предфисовхестейя Российся вха их обнамащимплять закого перавоз прусси, прившенную лиц вхопяетсям) и деграни, или пинцима (либока ка минящестимерситы, арбичет косущах воперанигостамов в имуществе или. Если предекно и соления), с ичляются сстральт собоимегла получения инфилиции.\r\n",
      " 2. Если счести в соопревей, с инеления;\r\n",
      " 13 настоящей перевате или избой подещения, нарушенных\r\n",
      "\r\n",
      " Тов жия содекствающах авместельи 1\r\n",
      " Лиценению прииями члекоб ос \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = u\"Человек обязан \"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 1000\n",
    "\n",
    "generate_sample(sampling_fun, seed, result_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
